{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04e668a9",
   "metadata": {},
   "source": [
    "# ðŸ©º Pneumonia Detection using InceptionResNetV2\n",
    "This notebook trains a deep learning model using **InceptionResNetV2** to detect Pneumonia from chest X-ray images, and deploys it with **Gradio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30088a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import libraries\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb133e67",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data generators\n",
    "data_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "val_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "\n",
    "# Directory paths\n",
    "TRAINING_DIR = '/kaggle/input/pneumonia-polenzo/dataset/chest_xray/train'\n",
    "TEST_DIR = '/kaggle/input/pneumonia-polenzo/dataset/chest_xray/test'\n",
    "im_shape = (299, 299)\n",
    "seed = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create generators\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    TRAINING_DIR, \n",
    "    target_size=im_shape, \n",
    "    shuffle=True, \n",
    "    seed=seed,\n",
    "    class_mode='categorical', \n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "validation_generator = val_data_generator.flow_from_directory(\n",
    "    TRAINING_DIR, \n",
    "    target_size=im_shape, \n",
    "    shuffle=False, \n",
    "    seed=seed,\n",
    "    class_mode='categorical', \n",
    "    batch_size=BATCH_SIZE, \n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_generator.flow_from_directory(\n",
    "    TEST_DIR, \n",
    "    target_size=im_shape, \n",
    "    shuffle=False, \n",
    "    seed=seed,\n",
    "    class_mode='categorical', \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Get dataset info\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "nb_test_samples = test_generator.samples\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "print('Classes: ' + str(classes))\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392701ef",
   "metadata": {},
   "source": [
    "## ðŸ§  Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe793809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model creation\n",
    "base_model = InceptionResNetV2(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(im_shape[0], im_shape[1], 3)\n",
    ")\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(200, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freezing pretrained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile model\n",
    "optimizer = Adam()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cabfac",
   "metadata": {},
   "source": [
    "## ðŸ‹ï¸ Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb11092",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training setup\n",
    "epochs = 10\n",
    "\n",
    "# Callbacks\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='model.keras',\n",
    "        monitor='val_loss', \n",
    "        save_best_only=True, \n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=10,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // BATCH_SIZE,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=validation_generator,\n",
    "    verbose=1,\n",
    "    validation_steps=nb_validation_samples // BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7875c5",
   "metadata": {},
   "source": [
    "## ðŸ“Š Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training history\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs_x = range(1, len(loss_values) + 1)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(epochs_x, loss_values, 'r', label='Training loss')\n",
    "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('EpochVsLoss.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "plt.plot(epochs_x, acc_values, 'r', label='Training acc')\n",
    "plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('EpochVsAcc.jpg', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d208dd",
   "metadata": {},
   "source": [
    "## ðŸš€ Gradio Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ad2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install and import Gradio\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('model.keras')  \n",
    "\n",
    "# Class names\n",
    "class_names = [\"Normal\", \"Pneumonia\"]  \n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    img = cv2.resize(image, (299, 299))  \n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# Prediction function\n",
    "def predict(image):\n",
    "    img_array = preprocess_image(image)\n",
    "    preds = model.predict(img_array)\n",
    "\n",
    "    if preds.shape[1] == 1:\n",
    "        confidence = float(preds[0][0])\n",
    "        label = class_names[1] if confidence > 0.5 else class_names[0]\n",
    "        confidence_display = confidence if confidence > 0.5 else 1 - confidence\n",
    "    else:\n",
    "        class_index = int(np.argmax(preds[0]))\n",
    "        label = class_names[class_index]\n",
    "        confidence_display = float(np.max(preds[0]))\n",
    "\n",
    "    return label, f\"Confidence: {confidence_display:.2f}\"\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Image(type=\"numpy\"),\n",
    "    outputs=[\"text\", \"text\"],\n",
    "    title=\"ðŸ©º Pneumonia Detection\",\n",
    "    description=\"Upload a chest X-ray image. The model will predict whether the image shows signs of Pneumonia or is Normal.\"\n",
    ")\n",
    "\n",
    "# Launch interface\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}